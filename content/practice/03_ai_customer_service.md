# Architecture 3: AI-Powered Customer Service System

## Use Case
**H·ªá th·ªëng CSKH th√¥ng minh v·ªõi AI**
- Chatbot 24/7 tr·∫£ l·ªùi t·ª± ƒë·ªông
- Ph√¢n t√≠ch sentiment c·ªßa kh√°ch h√†ng
- T√¨m ki·∫øm t√†i li·ªáu support th√¥ng minh
- Escalate sang agent ng∆∞·ªùi th·∫≠t khi c·∫ßn
- X·ª≠ l√Ω voice call (Speech-to-Text)

---

## Architecture Diagram

```mermaid
graph TB
    subgraph "Client Layer"
        Web[üí¨ Web Chat Widget]
        Mobile[üì± Mobile App]
        Phone[‚òéÔ∏è Phone IVR]
    end
    
    subgraph "API Layer"
        APIM[API Management<br/>Standard]
        SignalR[SignalR Service<br/>Real-time Chat]
    end
    
    subgraph "AI Services"
        OpenAI[Azure OpenAI<br/>GPT-4]
        CLU[Language Understanding<br/>CLU]
        Sentiment[Text Analytics<br/>Sentiment Analysis]
        Speech[Speech Service<br/>STT/TTS]
        Search[AI Search<br/>RAG Knowledge Base]
    end
    
    subgraph "Bot & Orchestration"
        BotService[Bot Framework<br/>Composer]
        Functions[Azure Functions<br/>Premium Plan]
    end
    
    subgraph "Data Layer"
        Cosmos[(Cosmos DB<br/>Chat History)]
        SQL[(Azure SQL<br/>Tickets/Analytics)]
        Blob[Blob Storage<br/>Voice Recordings]
    end
    
    subgraph "Integration"
        ServiceBus[Service Bus<br/>Premium]
        EventGrid[Event Grid<br/>Standard]
    end
    
    Web --> SignalR
    Mobile --> SignalR
    Phone --> Speech
    
    SignalR --> APIM
    APIM --> BotService
    Speech -->|Transcribed Text| BotService
    
    BotService --> CLU
    BotService --> Sentiment
    BotService --> OpenAI
    BotService --> Search
    
    BotService --> Cosmos
    BotService -->|Create Ticket| ServiceBus
    
    OpenAI -.->|RAG Query| Search
    Search -.->|FAQ/Docs| Blob
    
    Functions -->|Listen| ServiceBus
    Functions --> SQL
    Functions -->|Notify Agent| EventGrid
    
    style OpenAI fill:#10A37F
    style CLU fill:#0078D4
    style Search fill:#F25022
    style SignalR fill:#00BCF2
```

---

## Chi ti·∫øt Setup & Configuration

### 1. Azure OpenAI Service
**Model Deployment**: GPT-4 Turbo (128K context)

**T·∫°o Azure OpenAI:**
```bash
# T·∫°o resource (c·∫ßn approval t·ª´ Microsoft)
az cognitiveservices account create \
  --name openai-customer-service \
  --resource-group rg-ai-support \
  --location eastus \
  --kind OpenAI \
  --sku S0

# Deploy GPT-4 model
az cognitiveservices account deployment create \
  --name openai-customer-service \
  --resource-group rg-ai-support \
  --deployment-name gpt4-turbo \
  --model-name gpt-4 \
  --model-version "turbo-2024-04-09" \
  --model-format OpenAI \
  --sku-capacity 10 \
  --sku-name "Standard"
```

**System Prompt cho Customer Service Bot:**
```python
SYSTEM_PROMPT = """
B·∫°n l√† tr·ª£ l√Ω CSKH th√¢n thi·ªán v√† chuy√™n nghi·ªáp c·ªßa c√¥ng ty XYZ.

NGUY√äN T·∫ÆC:
1. Lu√¥n l·ªãch s·ª±, empathy v·ªõi kh√°ch h√†ng
2. Ch·ªâ tr·∫£ l·ªùi d·ª±a tr√™n t√†i li·ªáu ƒë∆∞·ª£c cung c·∫•p (context)
3. N·∫øu kh√¥ng bi·∫øt c√¢u tr·∫£ l·ªùi, th·ª´a nh·∫≠n v√† ƒë·ªÅ xu·∫•t chuy·ªÉn sang agent ng∆∞·ªùi
4. Kh√¥ng b·ªãa ƒë·∫∑t th√¥ng tin
5. H·ªèi l√†m r√µ n·∫øu c√¢u h·ªèi kh√¥ng r√µ r√†ng

FORMAT TR·∫¢ L·ªúI:
- Ng·∫Øn g·ªçn, s√∫c t√≠ch
- Bullet points n·∫øu c√≥ nhi·ªÅu b∆∞·ªõc
- K√®m link t√†i li·ªáu n·∫øu c√≥
"""
```

**Token Management & Cost Control:**
```python
# Gi·ªõi h·∫°n tokens ƒë·ªÉ tr√°nh chi ph√≠ cao
response = openai.ChatCompletion.create(
    model="gpt4-turbo",
    messages=[
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": user_message}
    ],
    max_tokens=500,  # Gi·ªõi h·∫°n output
    temperature=0.7,  # V·ª´a ƒë·ªß creative
    presence_penalty=0.6,  # Tr√°nh l·∫∑p l·∫°i
)
```

---

### 2. Azure AI Search (RAG - Knowledge Base)
**SKU**: Standard S1 (~$250/th√°ng)

**T·∫°o Search Service:**
```bash
az search service create \
  --name search-support-kb \
  --resource-group rg-ai-support \
  --sku Standard \
  --location eastasia \
  --partition-count 1 \
  --replica-count 2
```

**Indexer Pipeline (T·ª± ƒë·ªông import docs):**
```json
{
  "name": "support-docs-indexer",
  "dataSourceName": "blob-support-docs",
  "targetIndexName": "support-knowledge-base",
  "skillsetName": "text-enrichment-skillset",
  "schedule": {
    "interval": "PT2H"  // Ch·∫°y m·ªói 2 gi·ªù
  },
  "parameters": {
    "configuration": {
      "dataToExtract": "contentAndMetadata",
      "parsingMode": "default"
    }
  }
}
```

**Skillset (L√†m gi√†u d·ªØ li·ªáu b·∫±ng AI):**
```json
{
  "name": "text-enrichment-skillset",
  "skills": [
    {
      "@odata.type": "#Microsoft.Skills.Vision.OcrSkill",
      "context": "/document/normalized_images/*",
      "defaultLanguageCode": "vi",
      "detectOrientation": true
    },
    {
      "@odata.type": "#Microsoft.Skills.Text.MergeSkill",
      "context": "/document",
      "insertPreTag": " ",
      "insertPostTag": " "
    },
    {
      "@odata.type": "#Microsoft.Skills.Text.SplitSkill",
      "context": "/document/merged_content",
      "textSplitMode": "pages",
      "maximumPageLength": 2000,
      "pageOverlapLength": 500
    },
    {
      "@odata.type": "#Microsoft.Skills.Text.AzureOpenAIEmbeddingSkill",
      "context": "/document/pages/*",
      "resourceUri": "https://openai-customer-service.openai.azure.com",
      "deploymentId": "text-embedding-ada-002",
      "modelName": "text-embedding-ada-002"
    }
  ]
}
```

**Vector Search Configuration (Semantic Search):**
```json
{
  "name": "support-knowledge-base",
  "fields": [
    {"name": "id", "type": "Edm.String", "key": true},
    {"name": "title", "type": "Edm.String", "searchable": true},
    {"name": "content", "type": "Edm.String", "searchable": true},
    {"name": "contentVector", "type": "Collection(Edm.Single)", "dimensions": 1536, "vectorSearchProfile": "my-vector-profile"}
  ],
  "vectorSearch": {
    "algorithms": [
      {
        "name": "my-hnsw-algorithm",
        "kind": "hnsw",
        "hnswParameters": {
          "metric": "cosine",
          "m": 4,
          "efConstruction": 400,
          "efSearch": 500
        }
      }
    ],
    "profiles": [
      {
        "name": "my-vector-profile",
        "algorithm": "my-hnsw-algorithm"
      }
    ]
  }
}
```

**RAG Implementation - Retrieve & Generate:**
```python
async def answer_question(user_question: str, chat_history: list):
    # 1. Vector Search: T√¨m t√†i li·ªáu li√™n quan
    search_results = await search_client.search(
        search_text=user_question,
        vector_queries=[VectorizedQuery(
            vector=get_embedding(user_question),
            k_nearest_neighbors=5,
            fields="contentVector"
        )],
        select=["title", "content"],
        top=3
    )
    
    # 2. Build context t·ª´ search results
    context = "\n\n".join([
        f"[{doc['title']}]\n{doc['content']}" 
        for doc in search_results
    ])
    
    # 3. G·ª≠i v√†o GPT-4 v·ªõi context
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "system", "content": f"KNOWLEDGE BASE:\n{context}"},
        *chat_history,  # Previous conversation
        {"role": "user", "content": user_question}
    ]
    
    response = await openai_client.chat.completions.create(
        model="gpt4-turbo",
        messages=messages,
        temperature=0.7,
        max_tokens=500
    )
    
    return response.choices[0].message.content
```

---

### 3. Conversational Language Understanding (CLU)
**Use case**: Ph√¢n lo·∫°i intent v√† extract entities

**Training Data Example:**
```json
{
  "projectKind": "Conversation",
  "utterances": [
    {
      "text": "T√¥i mu·ªën h·ªßy ƒë∆°n h√†ng #12345",
      "intent": "CancelOrder",
      "entities": [
        {"category": "OrderNumber", "offset": 22, "length": 6, "text": "12345"}
      ]
    },
    {
      "text": "Ki·ªÉm tra tr·∫°ng th√°i ƒë∆°n",
      "intent": "CheckOrderStatus",
      "entities": []
    },
    {
      "text": "T√¥i c·∫ßn n√≥i chuy·ªán v·ªõi ng∆∞·ªùi th·∫≠t",
      "intent": "EscalateToAgent",
      "entities": []
    }
  ]
}
```

**Deploy & Use:**
```python
from azure.ai.language.conversations import ConversationAnalysisClient

clu_client = ConversationAnalysisClient(endpoint, credential)

async def classify_intent(user_message: str):
    result = await clu_client.analyze_conversation(
        task={
            "kind": "Conversation",
            "analysisInput": {
                "conversationItem": {
                    "text": user_message,
                    "id": "1",
                    "participantId": "user"
                }
            },
            "parameters": {
                "projectName": "customer-service-bot",
                "deploymentName": "production"
            }
        }
    )
    
    top_intent = result["prediction"]["topIntent"]
    confidence = result["prediction"]["intents"][0]["confidence"]
    entities = result["prediction"]["entities"]
    
    # Logic: N·∫øu intent r√µ r√†ng (confidence > 0.8), bypass GPT ƒë·ªÉ ti·∫øt ki·ªám
    if confidence > 0.8 and top_intent == "CheckOrderStatus":
        order_number = entities[0]["text"]
        return await get_order_status(order_number)  # Direct DB query
    else:
        # G·ª≠i v√†o GPT-4 ƒë·ªÉ x·ª≠ l√Ω ph·ª©c t·∫°p
        return await answer_question(user_message)
```

---

### 4. Azure AI Text Analytics (Sentiment Analysis)
**Use case**: Ph√°t hi·ªán kh√°ch h√†ng t·ª©c gi·∫≠n ‚Üí Escalate ngay

```python
from azure.ai.textanalytics import TextAnalyticsClient

async def analyze_sentiment(text: str):
    result = text_analytics_client.analyze_sentiment([text])[0]
    
    sentiment = result.sentiment  # positive, negative, neutral
    confidence_scores = result.confidence_scores
    
    # N·∫øu negative v·ªõi confidence cao ‚Üí chuy·ªÉn agent
    if sentiment == "negative" and confidence_scores.negative > 0.8:
        await escalate_to_human_agent({
            "reason": "Negative sentiment detected",
            "sentiment_score": confidence_scores.negative,
            "message": text
        })
        return "Ch√∫ng t√¥i r·∫•t xin l·ªói! T√¥i ƒëang k·∫øt n·ªëi b·∫°n v·ªõi chuy√™n vi√™n h·ªó tr·ª£..."
    
    return None
```

---

### 5. Azure SignalR Service (Real-time Chat)
**SKU**: Standard S1 (1000 concurrent connections) - ~$50/th√°ng

**T·∫°o SignalR:**
```bash
az signalr create \
  --name signalr-customer-chat \
  --resource-group rg-ai-support \
  --sku Standard_S1 \
  --unit-count 1 \
  --service-mode Serverless  # D√πng v·ªõi Azure Functions
```

**Azure Functions - SignalR Hub:**
```javascript
// negotiate function (client l·∫•y connection info)
module.exports = async function (context, req) {
    context.res = {
        body: context.bindings.signalRConnectionInfo
    };
};

// broadcast function (g·ª≠i message real-time)
module.exports = async function (context, req) {
    const message = req.body.message;
    const userId = req.body.userId;
    
    // G·ª≠i message ƒë·∫øn specific user
    context.bindings.signalRMessages = [{
        "target": "newMessage",
        "userId": userId,
        "arguments": [message]
    }];
};
```

---

### 6. Bot Framework Composer
**Visual Canvas ƒë·ªÉ design conversation flow**

**Dialog Flow Example:**
```yaml
# Main Dialog
- AdaptiveDialog:
    id: MainDialog
    triggers:
      - OnBeginDialog:
          actions:
            - SendActivity: "Xin ch√†o! T√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n?"
            - TextInput:
                property: user.question
      
      - OnIntent:
          intent: EscalateToAgent
          actions:
            - SendActivity: "T√¥i ƒëang k·∫øt n·ªëi b·∫°n v·ªõi chuy√™n vi√™n..."
            - HttpRequest:
                url: "https://api.crm.com/create-ticket"
                method: POST
                body:
                  userId: ${user.id}
                  question: ${user.question}
      
      - OnIntent:
          intent: CancelOrder
          actions:
            - ConfirmInput:
                property: user.confirmCancel
                prompt: "B·∫°n ch·∫Øc ch·∫Øn mu·ªën h·ªßy ƒë∆°n ${entities.orderNumber}?"
            - IfCondition:
                condition: user.confirmCancel == true
                actions:
                  - HttpRequest:
                      url: "https://api.orders.com/cancel"
                      method: POST
```

---

### 7. Speech Service (Voice Support)
**SKU**: Standard S0 (pay-per-use)

**Speech-to-Text (Realtime):**
```python
import azure.cognitiveservices.speech as speechsdk

# Config
speech_config = speechsdk.SpeechConfig(
    subscription=os.environ['SPEECH_KEY'],
    region="eastasia"
)
speech_config.speech_recognition_language = "vi-VN"

# Realtime recognition
async def recognize_from_phone():
    audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)
    recognizer = speechsdk.SpeechRecognizer(
        speech_config=speech_config,
        audio_config=audio_config
    )
    
    # Callback khi nh·∫≠n di·ªán ƒë∆∞·ª£c
    def recognized(evt):
        transcribed_text = evt.result.text
        # G·ª≠i text v√†o bot ƒë·ªÉ x·ª≠ l√Ω
        bot_response = await process_message(transcribed_text)
        
        # Text-to-Speech: ƒê·ªçc c√¢u tr·∫£ l·ªùi
        await speak_response(bot_response)
    
    recognizer.recognized.connect(recognized)
    recognizer.start_continuous_recognition()
```

**Text-to-Speech (Natural Voice):**
```python
async def speak_response(text: str):
    speech_config.speech_synthesis_voice_name = "vi-VN-HoaiMyNeural"  # Gi·ªçng n·ªØ t·ª± nhi√™n
    
    synthesizer = speechsdk.SpeechSynthesizer(
        speech_config=speech_config,
        audio_config=None  # Output to speaker
    )
    
    # SSML cho ƒëi·ªÅu ch·ªânh gi·ªçng ƒë·ªçc
    ssml = f"""
    <speak version='1.0' xml:lang='vi-VN'>
        <voice name='vi-VN-HoaiMyNeural'>
            <prosody rate='0.9' pitch='+5%'>
                {text}
            </prosody>
        </voice>
    </speak>
    """
    
    result = synthesizer.speak_ssml_async(ssml).get()
```

---

## Cosmos DB - Chat History Storage
**SKU**: Autoscale 400-4000 RU/s

**Schema:**
```json
{
  "id": "conv_123456",
  "userId": "user_789",
  "conversationId": "conv_123456",
  "messages": [
    {
      "timestamp": "2024-01-30T10:30:00Z",
      "role": "user",
      "content": "T√¥i mu·ªën h·ªßy ƒë∆°n h√†ng",
      "sentiment": "neutral"
    },
    {
      "timestamp": "2024-01-30T10:30:05Z",
      "role": "assistant",
      "content": "Vui l√≤ng cung c·∫•p m√£ ƒë∆°n h√†ng",
      "metadata": {
        "model": "gpt-4-turbo",
        "tokensUsed": 45
      }
    }
  ],
  "status": "active",
  "escalatedToAgent": false,
  "ttl": 2592000  // Auto-delete sau 30 ng√†y
}
```

**Partition Key**: `/userId` (m·ªói user c√≥ nhi·ªÅu conversation)

---

## Scaling & Performance

### 1. Cost Optimization
**Chi·∫øn l∆∞·ª£c ph√¢n t·∫ßng AI:**
- **Tier 1 (Cheap)**: CLU cho intent r√µ r√†ng ‚Üí Tr·∫£ l·ªùi template
- **Tier 2 (Medium)**: GPT-3.5 Turbo cho c√¢u h·ªèi ƒë∆°n gi·∫£n
- **Tier 3 (Expensive)**: GPT-4 cho c√¢u h·ªèi ph·ª©c t·∫°p

```python
async def smart_routing(user_message: str):
    # 1. CLU classify
    intent_result = await classify_intent(user_message)
    
    if intent_result.confidence > 0.9:
        # High confidence ‚Üí Template response (Free!)
        return TEMPLATES[intent_result.intent]
    
    # 2. Check complexity (word count, question type)
    if len(user_message.split()) < 15:
        # Simple question ‚Üí GPT-3.5
        return await call_gpt35_turbo(user_message)
    else:
        # Complex question ‚Üí GPT-4
        return await call_gpt4_turbo(user_message)
```

### 2. Caching Strategy
```python
# Cache GPT responses cho c√¢u h·ªèi ph·ªï bi·∫øn
cache_key = hashlib.md5(user_message.encode()).hexdigest()
cached_response = await redis.get(f"qa:{cache_key}")

if cached_response:
    return cached_response  # Ti·∫øt ki·ªám token cost!

# Cache miss ‚Üí call GPT
response = await openai_call(user_message)
await redis.setex(f"qa:{cache_key}", 3600, response)  # Cache 1 hour
```

---

## Chi ph√≠ ∆∞·ªõc t√≠nh (Monthly)

| Service | SKU | Gi√° |
|---------|-----|-----|
| Azure OpenAI GPT-4 | ~500K tokens/day | $450 |
| AI Search | Standard S1 | $250 |
| Speech Service | 100 hours STT | $100 |
| SignalR Service | Standard S1 | $50 |
| CLU | Standard (10K requests) | $15 |
| Text Analytics | 25K requests | $25 |
| Cosmos DB | 1000 RU/s avg | $58 |
| Azure Functions | Premium EP1 | $168 |
| Service Bus | Standard | $10 |
| **T·ªîNG** | | **~$1,126/th√°ng** |

*(Gi·∫£ s·ª≠ 50,000 conversations/th√°ng, m·ªói conversation 10 messages)*

---

## Security & Compliance

‚úÖ **PII Protection:**
- Mask credit card, phone trong logs
- D√πng **Azure Purview** ƒë·ªÉ scan sensitive data

‚úÖ **GDPR Compliance:**
- TTL 30 ng√†y cho chat history
- User c√≥ th·ªÉ request delete data

‚úÖ **Responsible AI:**
- Content Safety filter (block toxic content)
- Human review cho escalated cases
